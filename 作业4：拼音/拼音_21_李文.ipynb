{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import re\n",
    "import codecs\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "def get_list():\n",
    "    lj = []\n",
    "    py = []\n",
    "    data = []\n",
    "    wenzi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据库和构建创建数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pony.orm import *\n",
    "\n",
    "db = Database()\n",
    "\n",
    "class Hanzi(db.Entity):\n",
    "    id = PrimaryKey(int, auto=True)\n",
    "    Chinese = Optional(str,column ='Chinese')\n",
    "    spell = Optional(str,column ='spell')\n",
    "    link = Optional(str,column ='link')\n",
    "    \n",
    "def get_database():\n",
    "    dbpath = 'f:/ex9/hanzi.sqlite'\n",
    "    if os.path.exists(dbpath):\n",
    "        os.remove(dbpath)\n",
    "    f = open(dbpath,\"w\")\n",
    "    f.close()\n",
    "    db.bind(provider='sqlite',filename='f:/ex9/hanzi.sqlite')\n",
    "    db.generate_mapping(create_tables=True)\n",
    "    set_sql_debug(True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建查找汉字拼音，汉字发音链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spell(h):\n",
    "    reobj = re.compile(r'<span class=\"op_exactqa_detail_word_pronounce\">([\\d\\D]*?)<')\n",
    "    for match in reobj.finditer(h):\n",
    "        a = match.group(1)\n",
    "        py.append(a)\n",
    "def get_link(h):\n",
    "    reobj = re.compile(r\"\"\"data-click=\"{fm:'beha'}\" url=\"([\\d\\D]*?)\" h\"\"\")\n",
    "    for match in reobj.finditer(h):\n",
    "        a = match.group(1)\n",
    "        lj.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取页面html,并且获取汉字的发音链接和拼音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(a):\n",
    "    driver=webdriver.Chrome()\n",
    "    url=\"https://www.baidu.com/s?wd=\" + a + \"拼音\"\n",
    "    driver.get(url)\n",
    "    h==driver.page_source\n",
    "    \n",
    "    get_spell(h)\n",
    "    get_link(h)\n",
    "    \n",
    "    for i in range(len(lj)):\n",
    "        data.append(( a , py[i] , lj[i] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建打开txt文件，将文件中的字存入列表wenzi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hanzi():\n",
    "    f = codecs.open(r\"C:\\Users\\19148\\Desktop\\初始.txt\",\"r\",\"utf-8-sig\")\n",
    "    for hz in f.readlines():\n",
    "        a = hz.replace('\\r','').replace('\\n','')\n",
    "        wenzi.append(a)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建将文字存入csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv():\n",
    "    f = codecs.open(r\"f:\\999.csv\",\"w\",\"utf_8_sig\")\n",
    "    f.write(\"汉字,拼音,拼音发声的链接\\n\")\n",
    "    for data1 in data:\n",
    "        f.write(data1[0] + \",\" + data1[1] + \",\" + data1[2] + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务一：利用百度的汉字查找拼音功能，以元组形式输出出某个汉字对应的以下内容：（该汉字，拼音，拼音发声的链接）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_list()\n",
    "get_data(\"我\")\n",
    "data\n",
    "get_clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务二：在任务1的基础上进行延展，已知一个txt文本文件每行只有一个文字,从该文件逐行读取文字，并构建任务1的链接，抽取拼音及发音链接，构建一个CSV文件."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_list()\n",
    "get_hanzi()\n",
    "for a in wenzi:\n",
    "    lj.clear()\n",
    "    py.clear()\n",
    "    get_data(a)\n",
    "get_csv()\n",
    "get_clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务三：存储到数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_list()\n",
    "get_database()\n",
    "get_hanzi()\n",
    "for a in wenzi:\n",
    "    lj.clear()\n",
    "    py.clear()\n",
    "    get_data(a)\n",
    "for data1 in data:\n",
    "    s=Hanzi(Chinese = data1[0],spell = data1[1],link = data1[2])\n",
    "    db.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
